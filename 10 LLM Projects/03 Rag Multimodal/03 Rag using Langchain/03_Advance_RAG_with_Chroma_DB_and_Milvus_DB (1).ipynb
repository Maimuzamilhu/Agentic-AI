{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RJOS6RvzuKwK"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n"
      ],
      "metadata": {
        "id": "CHGwU12F20vA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n"
      ],
      "metadata": {
        "id": "4MG0mBH623Nd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(genai.list_models())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rUuewGOh25D8",
        "outputId": "db14b883-e6d1-4f73-f6a4-5531502a4353"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Model(name='models/chat-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 Chat (Legacy)',\n",
              "       description='A legacy text-only model optimized for chat conversations',\n",
              "       input_token_limit=4096,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
              "       temperature=0.25,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/text-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 (Legacy)',\n",
              "       description='A legacy model that understands text and generates text as an output',\n",
              "       input_token_limit=8196,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
              "       temperature=0.7,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/embedding-gecko-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding Gecko',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=1024,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedText', 'countTextTokens'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Latest',\n",
              "       description=('The original Gemini 1.0 Pro model. This model will be discontinued on '\n",
              "                    'February 15th, 2025. Move to a newer Gemini version.'),\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro',\n",
              "       description='The best model for scaling across a wide range of tasks',\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro',\n",
              "       description='The best model for scaling across a wide range of tasks',\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
              "       description=('The original Gemini 1.0 Pro model version that supports tuning. Gemini 1.0 '\n",
              "                    'Pro will be discontinued on February 15th, 2025. Move to a newer Gemini '\n",
              "                    'version.'),\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-vision-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n",
              "                    'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n",
              "                    'Move to a newer Gemini version.'),\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/gemini-pro-vision',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n",
              "                    'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n",
              "                    'Move to a newer Gemini version.'),\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/gemini-1.5-pro-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 '\n",
              "                    'million tokens.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro 001',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in May of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-pro-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Pro 002',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in September of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in May of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro-exp-0801',\n",
              "       base_model_id='',\n",
              "       version='exp-0801',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-pro-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling '\n",
              "                    'across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 001',\n",
              "       description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in May of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-001-tuning',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 001 Tuning',\n",
              "       description=('Version of Gemini 1.5 Flash that supports tuning, our fast and versatile '\n",
              "                    'multimodal model for scaling across diverse tasks, released in May of 2024.'),\n",
              "       input_token_limit=16384,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash',\n",
              "       description=('Alias that points to the most recent stable version of Gemini 1.5 Flash, our '\n",
              "                    'fast and versatile multimodal model for scaling across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Flash 002',\n",
              "       description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in September of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B 001',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, '\n",
              "                    'released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 8B Experimental 0827',\n",
              "       description=('Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our '\n",
              "                    'smallest and most cost effective Flash model. Replaced by '\n",
              "                    'Gemini-1.5-flash-8b-001 (stable).'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-exp-0924',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 8B Experimental 0924',\n",
              "       description=('Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our '\n",
              "                    'smallest and most cost effective Flash model. Replaced by '\n",
              "                    'Gemini-1.5-flash-8b-001 (stable).'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Experimental',\n",
              "       description='Gemini 2.0 Flash Experimental',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-exp-1206',\n",
              "       base_model_id='',\n",
              "       version='exp_1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-exp-1121',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-exp-1114',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp-01-21',\n",
              "       base_model_id='',\n",
              "       version='2.0-exp-01-21',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental 01-21',\n",
              "       description='Experimental release (January 21st, 2025) of Gemini 2.0 Flash Thinking',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.7,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0-exp-01-21',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental 01-21',\n",
              "       description='Experimental release (January 21st, 2025) of Gemini 2.0 Flash Thinking',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.7,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp-1219',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental',\n",
              "       description='Gemini 2.0 Flash Thinking Experimental',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.7,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/learnlm-1.5-pro-experimental',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='LearnLM 1.5 Pro Experimental',\n",
              "       description=('Alias that points to the most recent stable version of Gemini 1.5 Pro, our '\n",
              "                    'mid-size multimodal model that supports up to 2 million tokens.'),\n",
              "       input_token_limit=32767,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/embedding-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding 001',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/text-embedding-004',\n",
              "       base_model_id='',\n",
              "       version='004',\n",
              "       display_name='Text Embedding 004',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/aqa',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Model that performs Attributed Question Answering.',\n",
              "       description=('Model trained to return answers to questions that are grounded in provided '\n",
              "                    'sources, along with estimating answerable probability.'),\n",
              "       input_token_limit=7168,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateAnswer'],\n",
              "       temperature=0.2,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=40)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "\n",
        "result : Dict = genai.embed_content(\n",
        "    model=\"models/text-embedding-004\",\n",
        "    content=\"Pakistan zinda bad we love our country\",\n",
        "    task_type=\"retrieval_document\",\n",
        "    title=\"Embedding of single string\",\n",
        ")\n",
        "\n",
        "# # 1 input > 1 vector output\n",
        "# print(str(result[\"embedding\"])[:50], \"... TRIMMED]\")\n",
        "\n",
        "result['embedding']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8oKINKvL28x3",
        "outputId": "d2eda1e7-d7c2-42ee-a726-f5edbff8a3ce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.03838823,\n",
              " 0.052146558,\n",
              " -0.07062306,\n",
              " -0.037940446,\n",
              " 0.06602876,\n",
              " 0.003412638,\n",
              " 0.011060191,\n",
              " 0.011297473,\n",
              " 0.0088465065,\n",
              " 0.049196165,\n",
              " 0.026362207,\n",
              " 0.029781424,\n",
              " 0.103020616,\n",
              " 0.0018105474,\n",
              " 0.009687083,\n",
              " -0.1145385,\n",
              " 0.053375162,\n",
              " 0.027896093,\n",
              " -0.069912076,\n",
              " 0.033948876,\n",
              " 0.0021454412,\n",
              " -0.06642034,\n",
              " 0.04420987,\n",
              " -0.021766845,\n",
              " -0.05236885,\n",
              " 0.012519431,\n",
              " -0.006010968,\n",
              " -0.005167873,\n",
              " -0.0061494075,\n",
              " 0.0031098027,\n",
              " 0.025889847,\n",
              " 0.056373067,\n",
              " 0.046986956,\n",
              " -0.054916363,\n",
              " 0.02060043,\n",
              " 0.021911908,\n",
              " -0.028752202,\n",
              " 0.022969386,\n",
              " 0.0386514,\n",
              " -0.030484943,\n",
              " -0.089530766,\n",
              " 0.015129875,\n",
              " -0.06397387,\n",
              " 0.047075633,\n",
              " -0.013017894,\n",
              " -0.029871592,\n",
              " -0.0067695505,\n",
              " -0.0074492395,\n",
              " -0.0059240796,\n",
              " 0.03697813,\n",
              " 0.018429233,\n",
              " -0.001360107,\n",
              " -0.011460476,\n",
              " 0.011616342,\n",
              " -0.025911184,\n",
              " -0.05487599,\n",
              " -0.036950245,\n",
              " -0.009039906,\n",
              " 0.011936421,\n",
              " -0.002934238,\n",
              " -0.027310636,\n",
              " 6.6082706e-05,\n",
              " -0.020024965,\n",
              " -0.027493374,\n",
              " 0.002532368,\n",
              " -0.015001376,\n",
              " -0.076121554,\n",
              " 0.032683495,\n",
              " -0.092314504,\n",
              " 0.024527755,\n",
              " -0.0056760833,\n",
              " 0.012404534,\n",
              " -0.054892246,\n",
              " 0.0047428426,\n",
              " 0.027187724,\n",
              " -0.023102688,\n",
              " 0.039532688,\n",
              " -0.04834113,\n",
              " -0.032563046,\n",
              " 0.055642914,\n",
              " -0.06099361,\n",
              " 0.012322463,\n",
              " 0.05332948,\n",
              " 0.044791535,\n",
              " 0.0047311513,\n",
              " 0.03546266,\n",
              " -0.018310213,\n",
              " -0.012843131,\n",
              " -0.03281737,\n",
              " -0.015505913,\n",
              " 0.06564103,\n",
              " 0.004260769,\n",
              " 0.02080681,\n",
              " 0.015551341,\n",
              " 0.03284577,\n",
              " -0.037125297,\n",
              " -0.06909162,\n",
              " -0.12455734,\n",
              " 0.033198744,\n",
              " 0.08457165,\n",
              " -0.014386027,\n",
              " -0.03143208,\n",
              " 0.022384034,\n",
              " -0.004822828,\n",
              " 0.012416186,\n",
              " 0.031697378,\n",
              " -0.1066608,\n",
              " -0.022101557,\n",
              " -0.008450847,\n",
              " -0.0052436255,\n",
              " 0.0067770644,\n",
              " -0.058070153,\n",
              " 0.041524004,\n",
              " -0.028612824,\n",
              " 0.04088967,\n",
              " -0.028240833,\n",
              " -0.034067433,\n",
              " 0.051358417,\n",
              " -0.025877517,\n",
              " 0.028154515,\n",
              " 0.0060459366,\n",
              " 0.026830649,\n",
              " -0.00095973775,\n",
              " 0.017185919,\n",
              " 0.004395111,\n",
              " 0.016280279,\n",
              " 0.0176109,\n",
              " -0.009282771,\n",
              " 0.010105145,\n",
              " -0.03267479,\n",
              " 0.072818495,\n",
              " -0.04778589,\n",
              " 0.01858214,\n",
              " -0.0020002476,\n",
              " -0.05818697,\n",
              " -0.052377947,\n",
              " 0.0286922,\n",
              " -0.014589298,\n",
              " 0.060979374,\n",
              " 0.013860318,\n",
              " -0.0071884138,\n",
              " 0.018080251,\n",
              " -0.07651641,\n",
              " 0.0370387,\n",
              " 0.013180877,\n",
              " -0.021393348,\n",
              " -0.0080846,\n",
              " 0.025077287,\n",
              " -0.06951974,\n",
              " 0.02669913,\n",
              " -0.012492207,\n",
              " 0.01859013,\n",
              " 0.038992975,\n",
              " 0.0051947823,\n",
              " -0.047826,\n",
              " 0.018798502,\n",
              " 0.04019756,\n",
              " -0.039466992,\n",
              " 0.08624624,\n",
              " -0.00062756106,\n",
              " 0.058413763,\n",
              " -0.06800717,\n",
              " 0.029188514,\n",
              " 0.008827655,\n",
              " -0.035301555,\n",
              " -0.025547149,\n",
              " 0.025351042,\n",
              " -0.06396529,\n",
              " -0.024263415,\n",
              " -0.019369712,\n",
              " 0.013893803,\n",
              " -0.02715477,\n",
              " -0.009625998,\n",
              " -0.06395668,\n",
              " -0.058829118,\n",
              " -0.014857789,\n",
              " -0.06285088,\n",
              " -0.019081429,\n",
              " -0.025285693,\n",
              " -0.023807587,\n",
              " 0.10905102,\n",
              " 0.019630715,\n",
              " -0.018424971,\n",
              " -0.051695295,\n",
              " 0.02405902,\n",
              " -0.008708305,\n",
              " 0.013477974,\n",
              " 0.00955763,\n",
              " 0.012669435,\n",
              " 0.052519657,\n",
              " -0.04345961,\n",
              " -0.011683332,\n",
              " -0.01012757,\n",
              " 0.07052994,\n",
              " -0.0055598025,\n",
              " -0.06500708,\n",
              " -0.029050773,\n",
              " -0.020193106,\n",
              " -0.054957137,\n",
              " -0.041815933,\n",
              " 0.029825028,\n",
              " -0.0037500036,\n",
              " -0.04422032,\n",
              " -0.08507198,\n",
              " -0.025203163,\n",
              " -0.022711176,\n",
              " -0.07533748,\n",
              " 0.00038292477,\n",
              " 0.000574007,\n",
              " -0.023213899,\n",
              " -0.05437338,\n",
              " -0.020481981,\n",
              " 0.0309786,\n",
              " -0.03049663,\n",
              " 0.049754348,\n",
              " 0.01301958,\n",
              " 0.059735786,\n",
              " 0.013099316,\n",
              " 0.07402825,\n",
              " 0.0028997941,\n",
              " -0.0031488023,\n",
              " 0.030355373,\n",
              " -0.0345743,\n",
              " 0.027214795,\n",
              " 0.030471744,\n",
              " 0.00409395,\n",
              " -0.006666186,\n",
              " -0.026523612,\n",
              " 0.0037652112,\n",
              " -0.036769453,\n",
              " -0.016134802,\n",
              " 0.033313625,\n",
              " 0.0036026041,\n",
              " 0.016536806,\n",
              " 0.051247668,\n",
              " 0.090472534,\n",
              " 0.010181305,\n",
              " 0.030595109,\n",
              " 0.0070580146,\n",
              " -0.00865541,\n",
              " -0.013374387,\n",
              " 0.010765982,\n",
              " 0.048682828,\n",
              " 0.028028237,\n",
              " -0.020036707,\n",
              " -0.008994092,\n",
              " 0.012286691,\n",
              " 0.040086675,\n",
              " 0.008561659,\n",
              " -0.04989866,\n",
              " -0.03489145,\n",
              " -0.006646721,\n",
              " -0.031492487,\n",
              " -0.021983976,\n",
              " 0.0068252063,\n",
              " -0.055136193,\n",
              " 0.046041407,\n",
              " -0.014977839,\n",
              " 0.018520158,\n",
              " -0.0019085855,\n",
              " 0.036878396,\n",
              " -0.0765386,\n",
              " 0.008701385,\n",
              " -0.059513815,\n",
              " -0.060923666,\n",
              " -0.049235404,\n",
              " 0.004780061,\n",
              " 0.0044634817,\n",
              " 0.08013073,\n",
              " -0.03781426,\n",
              " -0.004155092,\n",
              " -0.07378796,\n",
              " -0.0062083392,\n",
              " 0.00019341962,\n",
              " 0.049237784,\n",
              " 0.016864326,\n",
              " 0.013317688,\n",
              " -0.020757375,\n",
              " 0.011082609,\n",
              " -0.046459932,\n",
              " -0.023551403,\n",
              " -0.0025574379,\n",
              " 0.023846528,\n",
              " -0.03697934,\n",
              " -0.018832024,\n",
              " -0.05554495,\n",
              " 0.017728858,\n",
              " -0.008121325,\n",
              " -0.021077035,\n",
              " -0.006830344,\n",
              " 0.03167001,\n",
              " 0.02122792,\n",
              " 0.053463276,\n",
              " -0.051008683,\n",
              " 0.033604734,\n",
              " 0.0053696907,\n",
              " 0.043874938,\n",
              " 0.0068859165,\n",
              " 0.035119798,\n",
              " -0.009732238,\n",
              " 0.006822771,\n",
              " 0.035985652,\n",
              " 0.010248646,\n",
              " 0.021891562,\n",
              " 0.032525573,\n",
              " 0.011882014,\n",
              " 0.05660894,\n",
              " -0.013528444,\n",
              " -0.013231257,\n",
              " -0.045601033,\n",
              " 0.048486833,\n",
              " 0.061330978,\n",
              " -0.013769018,\n",
              " -0.021071164,\n",
              " -0.05462211,\n",
              " -0.01022884,\n",
              " -0.16075553,\n",
              " 0.0055632093,\n",
              " -0.005055581,\n",
              " -0.0068281684,\n",
              " -0.03442759,\n",
              " 0.02271425,\n",
              " 0.016652118,\n",
              " 0.002752376,\n",
              " 0.043466292,\n",
              " 0.02711752,\n",
              " -0.016791742,\n",
              " -0.048889656,\n",
              " 0.03908195,\n",
              " -0.022985088,\n",
              " 0.012583863,\n",
              " 0.005726204,\n",
              " 0.023895126,\n",
              " -0.05023696,\n",
              " -0.00048284858,\n",
              " 0.008326804,\n",
              " -0.03993198,\n",
              " 0.013789181,\n",
              " 0.047209363,\n",
              " 0.027224733,\n",
              " -0.025249159,\n",
              " -0.0023370015,\n",
              " 0.043043554,\n",
              " 0.021095976,\n",
              " 0.03354987,\n",
              " -0.030191306,\n",
              " 0.02248958,\n",
              " -0.028729452,\n",
              " 0.05607367,\n",
              " -0.009501291,\n",
              " -0.023586508,\n",
              " 0.08498721,\n",
              " 0.0575211,\n",
              " -0.00075478735,\n",
              " -0.011939774,\n",
              " 0.0003264734,\n",
              " 0.060069848,\n",
              " -0.0073553207,\n",
              " 0.033479355,\n",
              " 0.0030075137,\n",
              " -0.01904192,\n",
              " -0.005860383,\n",
              " 0.023575183,\n",
              " 0.05215699,\n",
              " -5.4912136e-05,\n",
              " -0.060488857,\n",
              " -0.023957102,\n",
              " 0.012998325,\n",
              " 0.03517663,\n",
              " -0.035629902,\n",
              " 0.0369,\n",
              " 0.008402149,\n",
              " 0.001765194,\n",
              " 0.0023059861,\n",
              " 0.04675764,\n",
              " -0.04476126,\n",
              " -0.0069735753,\n",
              " -0.0002626759,\n",
              " 0.023913743,\n",
              " -0.02967791,\n",
              " 0.00031710474,\n",
              " -0.010220715,\n",
              " 0.009249499,\n",
              " 0.020453123,\n",
              " -0.03715475,\n",
              " 0.047895074,\n",
              " 0.001733521,\n",
              " 0.0037312186,\n",
              " 0.022507915,\n",
              " 0.06591765,\n",
              " -0.0115289455,\n",
              " 0.013562781,\n",
              " 0.057814762,\n",
              " 0.04246558,\n",
              " 5.7039684e-05,\n",
              " 0.033612076,\n",
              " -0.042697903,\n",
              " 0.0644634,\n",
              " -9.151293e-05,\n",
              " 0.037152737,\n",
              " -0.0011938581,\n",
              " -0.027302312,\n",
              " 0.09659006,\n",
              " 0.0012583006,\n",
              " -0.010336961,\n",
              " -0.061051127,\n",
              " 0.01347184,\n",
              " -0.0049233683,\n",
              " 0.008797497,\n",
              " 0.03161731,\n",
              " -0.03648881,\n",
              " -0.009932623,\n",
              " -0.07835084,\n",
              " 4.2173e-05,\n",
              " -0.03334824,\n",
              " 0.014768315,\n",
              " -0.015830249,\n",
              " 0.021433732,\n",
              " -0.025502263,\n",
              " 0.0038483543,\n",
              " -0.016326146,\n",
              " -0.014174781,\n",
              " -0.016782146,\n",
              " -0.020667074,\n",
              " 0.01614993,\n",
              " -0.08426387,\n",
              " -0.03154883,\n",
              " 0.01654426,\n",
              " 0.0670697,\n",
              " 0.042512123,\n",
              " 0.062353604,\n",
              " -0.030913549,\n",
              " 0.013138386,\n",
              " 0.026835408,\n",
              " 0.0110793365,\n",
              " -0.0218443,\n",
              " 0.026536738,\n",
              " -0.0064630304,\n",
              " -0.022492763,\n",
              " -0.035576217,\n",
              " -0.037078027,\n",
              " 0.01286653,\n",
              " -0.00037669428,\n",
              " 0.04966357,\n",
              " -0.0024665396,\n",
              " 0.0146915335,\n",
              " 0.06098033,\n",
              " -0.029980283,\n",
              " 0.0008697028,\n",
              " 0.064677365,\n",
              " -0.00428359,\n",
              " -0.01547883,\n",
              " -0.025234092,\n",
              " 0.025209295,\n",
              " -0.002039264,\n",
              " 0.03444799,\n",
              " -0.0022913783,\n",
              " 0.023588978,\n",
              " -0.045668975,\n",
              " 0.04170248,\n",
              " -0.044887327,\n",
              " -0.021114206,\n",
              " 0.045086056,\n",
              " 0.015677046,\n",
              " -0.0041803983,\n",
              " -0.02905689,\n",
              " -0.013574269,\n",
              " 0.070722766,\n",
              " -0.0015028456,\n",
              " -0.019128142,\n",
              " -0.026981374,\n",
              " -0.0075038965,\n",
              " 0.009927641,\n",
              " 0.011850352,\n",
              " -0.040748272,\n",
              " 0.029269002,\n",
              " 0.014578034,\n",
              " 0.04644106,\n",
              " -0.06513363,\n",
              " -0.047762387,\n",
              " 0.005994523,\n",
              " -0.016654402,\n",
              " -0.046001986,\n",
              " 0.033784177,\n",
              " -0.0059721963,\n",
              " -0.070746414,\n",
              " -0.016943036,\n",
              " -0.0011437157,\n",
              " 0.029320652,\n",
              " 0.08227695,\n",
              " 0.025052816,\n",
              " 0.0022991449,\n",
              " 0.011448173,\n",
              " -0.008304278,\n",
              " 0.019583032,\n",
              " -0.014954232,\n",
              " 0.030788248,\n",
              " 0.0029797773,\n",
              " -0.03788128,\n",
              " 0.03724129,\n",
              " 0.05528784,\n",
              " -0.034972087,\n",
              " -0.0019545844,\n",
              " -0.05261343,\n",
              " -0.056895804,\n",
              " 0.044773314,\n",
              " -0.063213706,\n",
              " -0.043816824,\n",
              " 0.0905643,\n",
              " -0.04863921,\n",
              " 0.046625808,\n",
              " 0.035758417,\n",
              " 0.011668098,\n",
              " 0.0079242475,\n",
              " -0.03298972,\n",
              " -0.011208986,\n",
              " -0.081154466,\n",
              " -0.0031484948,\n",
              " -0.017065778,\n",
              " 0.024816861,\n",
              " -0.06621424,\n",
              " -0.039437614,\n",
              " 0.042017188,\n",
              " -0.00050168845,\n",
              " 0.018247671,\n",
              " -0.024270063,\n",
              " -0.030748807,\n",
              " 0.02384947,\n",
              " 0.008581831,\n",
              " -0.032525916,\n",
              " -0.003901744,\n",
              " 0.036596827,\n",
              " 0.022501571,\n",
              " 0.014229588,\n",
              " -0.0061629214,\n",
              " 0.047474425,\n",
              " 0.01413304,\n",
              " 0.0031166582,\n",
              " 0.040364627,\n",
              " -0.019387295,\n",
              " 0.014101074,\n",
              " -0.008786798,\n",
              " -0.029672347,\n",
              " 0.02951629,\n",
              " 0.02604202,\n",
              " 0.04345717,\n",
              " -0.060620695,\n",
              " 0.025450386,\n",
              " -0.015682898,\n",
              " 0.028722597,\n",
              " -0.008685122,\n",
              " -0.010794636,\n",
              " -0.012771901,\n",
              " -0.0011217573,\n",
              " 0.005098702,\n",
              " -0.04036902,\n",
              " -0.02358411,\n",
              " -0.0033144718,\n",
              " -0.0679191,\n",
              " -0.020438666,\n",
              " -0.019104637,\n",
              " -0.03788486,\n",
              " 0.0044292295,\n",
              " 0.022491189,\n",
              " 0.0033494795,\n",
              " -0.046392314,\n",
              " 0.03587325,\n",
              " 0.04138297,\n",
              " 0.0287248,\n",
              " -0.0068671093,\n",
              " -0.0005605311,\n",
              " 0.011639575,\n",
              " 0.024345625,\n",
              " -0.060927104,\n",
              " 0.04197428,\n",
              " 0.015342221,\n",
              " -0.018747458,\n",
              " 0.008443097,\n",
              " 0.055946324,\n",
              " -0.005637669,\n",
              " 0.054343686,\n",
              " 0.018478725,\n",
              " 0.037477393,\n",
              " -0.04967184,\n",
              " 0.02941245,\n",
              " 0.010871435,\n",
              " 0.032436363,\n",
              " 0.0059494562,\n",
              " 0.04422599,\n",
              " -0.006740689,\n",
              " -0.02163518,\n",
              " 0.022332964,\n",
              " 0.017083554,\n",
              " -0.0512461,\n",
              " -0.05113343,\n",
              " -0.0320302,\n",
              " -0.048574947,\n",
              " -0.017281223,\n",
              " 0.007265277,\n",
              " -0.025888035,\n",
              " 0.0499955,\n",
              " -0.028761506,\n",
              " 0.047641512,\n",
              " 0.006997258,\n",
              " -0.055606503,\n",
              " -0.117244676,\n",
              " -0.010426683,\n",
              " -0.028365433,\n",
              " -0.018504485,\n",
              " -0.009055795,\n",
              " -0.014238359,\n",
              " -0.015719526,\n",
              " -0.03149241,\n",
              " -0.003400495,\n",
              " -0.012937613,\n",
              " -0.018243145,\n",
              " -0.0144358035,\n",
              " -0.0056894287,\n",
              " 0.054088052,\n",
              " 0.011907005,\n",
              " -0.002125421,\n",
              " -0.01782156,\n",
              " 0.0037183985,\n",
              " -0.054034688,\n",
              " -0.012775008,\n",
              " -0.020216625,\n",
              " -0.023934435,\n",
              " 0.017653301,\n",
              " 0.0046870117,\n",
              " 0.027500125,\n",
              " 0.012845098,\n",
              " 0.022624854,\n",
              " 0.03215435,\n",
              " -0.016278284,\n",
              " 0.017207153,\n",
              " 0.022287257,\n",
              " -0.004011496,\n",
              " -0.021268496,\n",
              " 0.018312145,\n",
              " -0.003118074,\n",
              " -0.0376296,\n",
              " -0.023842245,\n",
              " 0.025278052,\n",
              " 0.0063156355,\n",
              " -0.03015189,\n",
              " 0.031874474,\n",
              " -0.008299831,\n",
              " -0.0011517438,\n",
              " 0.0062523056,\n",
              " -0.00044700058,\n",
              " -0.016225612,\n",
              " -0.032361522,\n",
              " 0.020232819,\n",
              " -0.011365004,\n",
              " -0.025918007,\n",
              " 0.033456538,\n",
              " -0.0038194235,\n",
              " -0.04559527,\n",
              " 0.0091817845,\n",
              " -0.05172906,\n",
              " 0.0042541544,\n",
              " -0.020796109,\n",
              " 0.041575905,\n",
              " 0.022975706,\n",
              " -0.021847228,\n",
              " -0.007324385,\n",
              " -0.011522168,\n",
              " -0.055374276,\n",
              " 0.026773449,\n",
              " -0.020385416,\n",
              " 0.03198812,\n",
              " -0.02696582,\n",
              " 0.02701983,\n",
              " 0.032033257,\n",
              " -0.025706427,\n",
              " -0.028448839,\n",
              " 0.0704481,\n",
              " -0.023736434,\n",
              " -0.047385562,\n",
              " 0.033373505,\n",
              " -0.010090002,\n",
              " -0.027287053,\n",
              " -0.015427962,\n",
              " -0.04851017,\n",
              " 0.036831185,\n",
              " -0.012953718,\n",
              " 0.022658195,\n",
              " -0.021795256,\n",
              " 0.02059936,\n",
              " 0.024475915,\n",
              " 0.00055408303,\n",
              " -0.026111007,\n",
              " -0.03636221,\n",
              " -0.016248602,\n",
              " 0.030392338,\n",
              " 0.07902486,\n",
              " -0.024101842,\n",
              " 0.0055876803,\n",
              " -0.008215156,\n",
              " -0.023136614,\n",
              " -0.030492572,\n",
              " -0.0022403337,\n",
              " -0.035763245,\n",
              " -0.03326536,\n",
              " 0.0021086684,\n",
              " -0.010088928,\n",
              " -0.008121419,\n",
              " 0.0019507741,\n",
              " -0.073499575,\n",
              " 0.049395718,\n",
              " 0.023999428,\n",
              " -0.0007134775,\n",
              " 0.032879937,\n",
              " -0.00640119,\n",
              " 0.02869106,\n",
              " 0.013808199,\n",
              " 0.023221033,\n",
              " -0.01590115,\n",
              " 0.023822999,\n",
              " 0.08655637,\n",
              " -0.04039015,\n",
              " 0.03261114,\n",
              " 0.017652059,\n",
              " 0.03452416,\n",
              " 0.02047702,\n",
              " -0.039462328,\n",
              " -0.04694545,\n",
              " 0.038026884,\n",
              " -0.047012918,\n",
              " 0.074192934,\n",
              " 0.05681196,\n",
              " 0.0008074619,\n",
              " -0.046055894,\n",
              " 0.05716265,\n",
              " -0.019507777,\n",
              " -0.031380996,\n",
              " -0.024576735,\n",
              " -0.0037123791,\n",
              " -0.03486795,\n",
              " 0.02585528,\n",
              " 0.05651957,\n",
              " -0.054238588,\n",
              " -0.06553499,\n",
              " -0.023791313,\n",
              " -0.0122753875,\n",
              " 0.009531079,\n",
              " -0.031291775,\n",
              " -0.045523264,\n",
              " -0.015830627,\n",
              " -0.04805145,\n",
              " -0.059642047,\n",
              " 0.029825516,\n",
              " 0.05650545,\n",
              " 0.019484732,\n",
              " 0.073890746,\n",
              " 0.009196346,\n",
              " 0.030793106,\n",
              " -0.03390429,\n",
              " 0.024764318,\n",
              " 0.061629165,\n",
              " -0.043743283,\n",
              " 0.0106486445,\n",
              " 0.010411605,\n",
              " 0.0031037293,\n",
              " -0.05513253,\n",
              " -0.04937317,\n",
              " 0.004930977,\n",
              " -0.008528327]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(result['embedding'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25QOkgA-3ENl",
        "outputId": "8240910c-b997-4b56-cdab-c7b8dedc0d5e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "\n",
        "result : Dict = genai.embed_content(\n",
        "    model=\"models/text-embedding-004\",\n",
        "    content=[\n",
        "        \"What is the meaning of life?\",\n",
        "        \"How much wood would a woodchuck chuck?\",\n",
        "        \"How does the brain work?\",\n",
        "    ],\n",
        "    task_type=\"retrieval_document\",\n",
        "    title=\"Embedding of list of strings\",\n",
        ")\n",
        "\n",
        "# A list of inputs > A list of vectors output\n",
        "for v in result[\"embedding\"]:\n",
        "    print(str(v)[:50], \"... TRIMMED ...\", len(v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "0PwqA1UA3LUJ",
        "outputId": "7f47a5a0-aed0-4489-b79c-8399ba0d9ac8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.036453027, 0.033254996, -0.03970925, -0.002628 ... TRIMMED ... 768\n",
            "[-0.01591948, 0.032582663, -0.081024624, -0.011298 ... TRIMMED ... 768\n",
            "[0.00037063024, 0.03763057, -0.122695684, -0.00951 ... TRIMMED ... 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Vector Stores & Retreival using Chroma DB and Langchain\n"
      ],
      "metadata": {
        "id": "55nfQxrl3TVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq langchain-chroma\n"
      ],
      "metadata": {
        "id": "1F2qzGwp3O-M"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import getpass\n",
        "import os\n"
      ],
      "metadata": {
        "id": "ZA6lhcGa3Wl6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install pypdf\n",
        "!pip install langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tnePWieB0dL",
        "outputId": "95a87cd8-76be-4c0e-89c1-b8f288582025"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.1.0)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.15)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.11)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.15)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.31 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.31)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.25.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.15->langchain-community) (0.3.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.15->langchain-community) (2.10.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.14)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.31->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.15->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.15->langchain-community) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load doc"
      ],
      "metadata": {
        "id": "DOCbj4nfGi8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader(\"/content/Panaversity Cloud Native Applied Generative and Agentic AI Engineer (1).pdf\")\n",
        "pages = loader.load_and_split()\n",
        "docs = loader.load()\n"
      ],
      "metadata": {
        "id": "yf1ZLQW6B55f"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split doc"
      ],
      "metadata": {
        "id": "v9cqc_zAGkt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "kbCuwYmbDrxu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq langchain-google-genai\n"
      ],
      "metadata": {
        "id": "zmshFLKq3dLG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\",\n",
        "                                          google_api_key=userdata.get('GOOGLE_API_KEY'))"
      ],
      "metadata": {
        "id": "4hqgEWKx3fZJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embeddings.embed_query(\"What's our Q1 revenue?\")"
      ],
      "metadata": {
        "id": "G1Tveumf_YB7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embd doc"
      ],
      "metadata": {
        "id": "ZCZXDYdbGoJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "# from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents = splits,\n",
        "    embedding=embeddings)"
      ],
      "metadata": {
        "id": "62K69Rpl_Z4e"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(dir(vectorstore))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9bUT64-_dyz",
        "outputId": "e3a597a1-d71c-4639-94d8-d0b5d244ae8c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_Chroma__ensure_collection',\n",
              " '_Chroma__query_collection',\n",
              " '_LANGCHAIN_DEFAULT_COLLECTION_NAME',\n",
              " '__abstractmethods__',\n",
              " '__annotations__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_asimilarity_search_with_relevance_scores',\n",
              " '_chroma_collection',\n",
              " '_client',\n",
              " '_client_settings',\n",
              " '_collection',\n",
              " '_collection_metadata',\n",
              " '_collection_name',\n",
              " '_cosine_relevance_score_fn',\n",
              " '_embedding_function',\n",
              " '_euclidean_relevance_score_fn',\n",
              " '_get_retriever_tags',\n",
              " '_max_inner_product_relevance_score_fn',\n",
              " '_persist_directory',\n",
              " '_select_relevance_score_fn',\n",
              " '_similarity_search_with_relevance_scores',\n",
              " 'aadd_documents',\n",
              " 'aadd_texts',\n",
              " 'add_documents',\n",
              " 'add_images',\n",
              " 'add_texts',\n",
              " 'adelete',\n",
              " 'afrom_documents',\n",
              " 'afrom_texts',\n",
              " 'aget_by_ids',\n",
              " 'amax_marginal_relevance_search',\n",
              " 'amax_marginal_relevance_search_by_vector',\n",
              " 'as_retriever',\n",
              " 'asearch',\n",
              " 'asimilarity_search',\n",
              " 'asimilarity_search_by_vector',\n",
              " 'asimilarity_search_with_relevance_scores',\n",
              " 'asimilarity_search_with_score',\n",
              " 'delete',\n",
              " 'delete_collection',\n",
              " 'embeddings',\n",
              " 'encode_image',\n",
              " 'from_documents',\n",
              " 'from_texts',\n",
              " 'get',\n",
              " 'get_by_ids',\n",
              " 'max_marginal_relevance_search',\n",
              " 'max_marginal_relevance_search_by_vector',\n",
              " 'override_relevance_score_fn',\n",
              " 'reset_collection',\n",
              " 'search',\n",
              " 'similarity_search',\n",
              " 'similarity_search_by_image',\n",
              " 'similarity_search_by_image_with_relevance_score',\n",
              " 'similarity_search_by_vector',\n",
              " 'similarity_search_by_vector_with_relevance_scores',\n",
              " 'similarity_search_with_relevance_scores',\n",
              " 'similarity_search_with_score',\n",
              " 'similarity_search_with_vectors',\n",
              " 'update_document',\n",
              " 'update_documents']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z4AFL29_g-W",
        "outputId": "12a6f8fa-77c2-4331-eb9a-75dd569f72bb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_chroma.vectorstores.Chroma at 0x7c98a0d8e6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore.similarity_search(\"python\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tqk6lvr_kfN",
        "outputId": "dcd83170-ca41-46a7-ec1b-25ee150fc5c1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='69c12aea-b181-4eea-a78b-5d865d47da1a', metadata={'page': 13, 'page_label': '14', 'source': '/content/Panaversity Cloud Native Applied Generative and Agentic AI Engineer (1).pdf'}, page_content=\"5.Whydon'tweuseTypeScript(Node.js)todevelopAPIsinsteadofusingPython?WewillnotuseTypescriptinGenAIAPIdevelopmentbecausePythonisaprioritywiththeAIcommunitywhenworkingwithAIandifanyupdatescomeinlibrariestheywillfirstcomeforPython.PythonisalwaysabetterchoicewhendealingwithAIandAPI.\\n PythonisthedefactostandardforAIDevelopment. TypeScriptisamoremodernlanguagethatisgainingpopularityforWebDevelopment,butPythonismorewidelyusedandhasalargerecosystemoflibrariesandframeworksavailable,especiallyforAI. TypeScriptisusedforwebuserinterfaces,whilePythonisusedforAPIs. Inthesecondquarter, studentswilllearntodevelopAPIsusingPythoninsteadofTypeScript. PythonisamorecommonlyusedlanguageforAIandAPIdevelopment,andithasalargerecosystemoflibrariesandframeworksavailableforthesepurposes. TypeScriptisamoremodernlanguagethatisbecomingincreasinglypopularforAPIdevelopmentalso,butitisstillnotaswidelyusedasPython,especiallyforAIapplicationsanddevelopment.\\n14\"),\n",
              " Document(id='89229868-63d3-4a6e-a83f-0e98007895e2', metadata={'page': 30, 'page_label': '31', 'source': '/content/Panaversity Cloud Native Applied Generative and Agentic AI Engineer (1).pdf'}, page_content='3.CommunityandEcosystem:- PyTorch:Hasseenrapidadoptionintheresearchcommunity, leadingtoarichecosystemoftools,libraries,andcommunitysupport.LibrarieslikeHuggingFacesTransformersarebuiltprimarilyforPyTorch,offeringextensivesupportforLLMs.- TensorFlow:Hasastrongindustrialpresenceandiswidelyusedinproductionenvironments.However, theresearchcommunityhasincreasinglyfavouredPyTorch.\\n4.IntegrationwithHuggingFace:\\n31'),\n",
              " Document(id='db83ff63-d3be-46e0-a3ed-8f1cfe8ea8c5', metadata={'page': 3, 'page_label': '4', 'source': '/content/Panaversity Cloud Native Applied Generative and Agentic AI Engineer (1).pdf'}, page_content=' Certification: CertifiedProfessionalPythonProgrammer(CPPP1)\\nLearningRepo:https://github.com/panaversity/learn-cloud-native-modern-python\\n Quarter2:DevelopingMultiAgentSystems\\nWiththiscourse,youllstartbybuildingastrongunderstandingofgenerativeAIandlearnhowtoapplyLargelanguagemodels(LLMs)anddiffusionmodelspractically. Wewillintroduceasetofprinciplesknownaspromptengineering,whichwillhelpdeveloperstoworkefficientlywithAI.LearntocreatecustomAImodelsandGPTsusingOpenAI,Azure,andGoogletechnologies.Useopensourcelibraries,likeLangchain,andLangGraphto\\n4'),\n",
              " Document(id='aba13701-4e7e-49a9-887f-99c1bd3452b3', metadata={'page': 28, 'page_label': '29', 'source': '/content/Panaversity Cloud Native Applied Generative and Agentic AI Engineer (1).pdf'}, page_content='PyTorchPyTorchisanopen-sourcedeeplearningframeworkdevelopedbyFacebooksAIResearchlab.Itprovidesaflexibleandefficientplatformforbuildingandtrainingneuralnetworks.\\nImportanceinFine-TuningLLMs:1.DynamicComputationGraphs:PyTorchsdynamiccomputationgraph(alsoknownasdefine-by-run)allowsforflexibilityandeaseofdebugging.Thisisparticularlyusefulwhenexperimentingwithdifferentmodelarchitecturesandtrainingstrategies.2.ExtensiveLibrariesandTools:PyTorchhasawiderangeoflibrariesandtoolsthatfacilitatevariousdeeplearningtasks,includingnaturallanguageprocessing(NLP).LibrarieslikeHuggingFacesTransformersarebuiltontopofPyTorch,providingpre-trainedmodelsandutilitiesforfine-tuning.3.GPUAcceleration:PyTorchsupportsGPUacceleration,whichisessentialforhandlingthelargecomputationalrequirementsoffine-tuningLLMs.4.CommunityandEcosystem:PyTorchhasastrongcommunityandextensivedocumentation,makingiteasiertofindresources,tutorials,andsupportforfine-tuningtasks.')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "await vectorstore.asimilarity_search(\"cloud\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BWrA3sf_mns",
        "outputId": "0b822899-f8b4-46d6-9251-7dc2c76b2621"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='47f7aa46-99ac-4bd0-a082-d8b989bd5bbe', metadata={'page': 5, 'page_label': '6', 'source': '/content/Panaversity Cloud Native Applied Generative and Agentic AI Engineer (1).pdf'}, page_content=\"Amazonisstillthecloudkingbasedonmarketshare.Butmanyanalystsagree:Inthebattleforthecloud,AIisnowagame-changerandAmazon'smaincompetitors,particularlyMicrosoft,havethemomentum.\\nInourprogramwewillbeusingAzureasourdefaultproviderforteachinganddeployment.Wewillbeusingusingtheseservices:\\nGetafreeAzureAccountnow:https://azure.microsoft.com/en-us/freeNote:UseGitHubAccounttostartanAzurefreetrial\\nAzureContainerApps(WewillStartfromthisserviceusingDaprandKeda)https://azure.microsoft.com/en-us/products/container-appsGetstartedwiththefreetier:Thefirst180,000vCPUpersecond,360,000GiB/s,and2millionrequestseachmontharefree.Watch:https://www.youtube.com/watch?v=0HwQfsa03K8Deploy:https://learn.microsoft.com/en-us/azure/container-apps/code-to-cloud-options\\nAzureContainerRegistryhttps://azure.microsoft.com/en-us/products/container-registry/\\nDeploytoAzureContainerAppswithGitHubActionshttps://learn.microsoft.com/en-us/azure/container-apps/github-actions\"),\n",
              " Document(id='be6fe7b9-a761-41df-952e-d4345c023655', metadata={'page': 19, 'page_label': '20', 'source': '/content/Panaversity Cloud Native Applied Generative and Agentic AI Engineer (1).pdf'}, page_content='5.CustomizationandControl:- FullControl:Open-sourcetoolsgiveyoucompletecontroloveryourinfrastructureanddeploymentpipelines.Youcancustomiseandextendthefunctionalitytosuitspecificrequirements.- Transparency:Accesstothesourcecodemeansyoucanauditandmodifythesoftwaretomeetyoursecurityandcomplianceneeds.\\nAdvantagesofUsingAWS,Azure,orGoogleCloudTechnologies\\n1.ManagedServices:- **EaseofUse:**Cloudprovidersofferawiderangeofmanagedservicesthatabstractawaythecomplexityofsettingupandmanaginginfrastructure.Thiscansavetimeandreduceoperationaloverhead.- IntegratedSolutions:Theseplatformsprovideintegratedservicesandtools,suchasdatabases,machinelearning,analytics,andmonitoring,whichcanbeeasilycombinedtobuildcomplexapplications.\\n2.ScalabilityandReliability:- GlobalInfrastructure:Cloudprovidershaveextensiveglobalinfrastructure,ensuringhighavailability, redundancy, andlowlatency.- Auto-Scaling:Advancedauto-scalingcapabilitiescandynamicallyadjustresourcestomeetchangingdemands,ensuringoptimalperformance.'),\n",
              " Document(id='1b14ee2f-1bb1-472e-bbaf-ab4e4b7c6209', metadata={'page': 20, 'page_label': '21', 'source': '/content/Panaversity Cloud Native Applied Generative and Agentic AI Engineer (1).pdf'}, page_content='- Built-InSecurity:Cloudprovidersofferrobustsecurityfeatures,includingidentityandaccessmanagement,encryption,andcompliancecertifications,helpingtoprotectyourdataandmeetregulatoryrequirements.- AutomaticUpdates:Managedservicesoftenincludeautomaticupdatesandpatches,reducingtheriskofsecurityvulnerabilities.\\n4.InnovationandSupport:- Cutting-EdgeTechnology:Majorcloudproviderscontinuouslyinnovateandintroducenewservicesandfeatures,allowingyoutoleveragethelatesttechnologieswithoutsignificantinvestment.- SupportandSLA:ComprehensivesupportservicesandServiceLevelAgreements(SLAs)ensurethatyouhaveaccesstoexperthelpandguaranteeduptime.\\nConclusion\\nChoosingbetweenopen-sourcetechnologieslikeDocker, Kubernetes,andTerraformversusproprietarycloudservicesfromAWS,Azure,orGoogleClouddependsonyourspecificneedsandpriorities.'),\n",
              " Document(id='78cd6ed6-f4fe-4692-b19d-487e4f1176b1', metadata={'page': 20, 'page_label': '21', 'source': '/content/Panaversity Cloud Native Applied Generative and Agentic AI Engineer (1).pdf'}, page_content='Conclusion\\nChoosingbetweenopen-sourcetechnologieslikeDocker, Kubernetes,andTerraformversusproprietarycloudservicesfromAWS,Azure,orGoogleClouddependsonyourspecificneedsandpriorities.\\n- OpenTechnologies:Offerportability, costefficiency, customization,andcontrol,makingthemidealformulti-cloudstrategies,avoidingvendorlock-in,andhavingmorecontroloveryourinfrastructure.- CloudProviders:Provideeaseofuse,managedservices,scalability,security, andaccesstocutting-edgetechnology, whichcanbeadvantageousforrapiddevelopment,scaling,andleveragingadvancedservices.\\nInmanycases,ahybridapproachthatcombinesthestrengthsofbothopen-sourcetoolsandcloudproviderservicescanprovidethebestofbothworlds,allowingyoutooptimiseforcost,flexibility, andinnovation.')]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note that providers implement different scores; Chroma here\n",
        "# returns a distance metric that should vary inversely with\n",
        "# similarity.\n",
        "\n",
        "vectorstore.similarity_search_with_score(\"langchain\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEqIx27c_oBU",
        "outputId": "87893771-b254-4af6-9799-797bc8686c9a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Document(id='e3690a43-1e88-49ba-8be1-f8efbbc36e94', metadata={'page': 14, 'page_label': '15', 'source': '/content/Panaversity Cloud Native Applied Generative and Agentic AI Engineer (1).pdf'}, page_content='LangChainisaplatformthatallowsyoutointeractwithvariouslanguagemodelsfromdifferentproviderssuchasOpenAI,GoogleGemini,HuggingFaceTransformers,etc.YoucanuseLangChaintocreateapplicationsthatleveragethepowerofnaturallanguageprocessingwithouthavingtodealwiththecomplexityofAPIsorSDKs.LangChainprovidesauser-friendlyinterfacethatletsyouchoosethemodelyouwanttouse,customizetheparametersyouwanttoapply, andseetheresultsinreal-time.\\n15'),\n",
              "  0.45153141021728516),\n",
              " (Document(id='15c83ad5-2087-4973-9ae1-85408229b7d6', metadata={'page': 14, 'page_label': '15', 'source': '/content/Panaversity Cloud Native Applied Generative and Agentic AI Engineer (1).pdf'}, page_content='6.WhatisthedifferencebetweenOpenAICompletionAPI,OpenAIAssistantAPI,GoogleGeminiMulti-ModalAPI,andLangChain?ThedifferencebetweenOpenAICompletionAPI,OpenAIAssistantAPI,GoogleGeminiMulti-ModalAPI,andLangChainisthattheyaredifferentwaysofusingartificialintelligencetogeneratetext,images,audio,andvideobasedonsomeinput,buttheyhavedifferentfeaturesandapplications.Hereisasummaryofeachone:\\nOpenAICompletionAPIisthemostfundamentalOpenAImodelthatprovidesasimpleinterfacethatsextremelyflexibleandpowerful.Yougiveitapromptanditreturnsatextcompletion,generatedaccordingtoyourinstructions.Youcanthinkofitasaveryadvancedautocompletewherethelanguagemodelprocessesyourtextpromptandtriestopredictwhatsmostlikelytocomenext.TheCompletionAPIcanbeusedforvarioustaskssuchaswritingstories,poems,essays,code,lyrics,etc.Italsosupportsdifferentmodelswithdifferentlevelsofpowersuitablefordifferenttasks.'),\n",
              "  0.7924563884735107),\n",
              " (Document(id='9100ea29-b54a-4005-9288-f82fa210ed19', metadata={'page': 6, 'page_label': '7', 'source': '/content/Panaversity Cloud Native Applied Generative and Agentic AI Engineer (1).pdf'}, page_content='II.CloudNativeGenAIMasteryLevel(3Quarters)\\n Quarter4:GenerativeAIwithPyTorch:\\nGenerativeAItoolslikeChatGPT, Gemini,andDALL-Ehaverevolutionisedourprofessionallandscape.Thishands-oncourse,MasterGenerativeAIwithPyTorch,guidesyouthroughtheexcitingprocessofbuildingandtrainingAImodelsusingPythonandtheversatile,open-sourcePyTorchframework,allwiththehardwareyoualreadyhave.YoulldelveintothecoreconceptsofGenerativeAdversarialNetworks(GANs),Transformers,LargeLanguageModels(LLMs),variationalautoencoders,diffusionmodels,LangChain,andmore.Alongtheway, youllgainpracticalexperienceandadeepunderstandingofthesecutting-edgetechnologies.\\nLearningRepo:https://github.com/panaversity/genai-with-pytorch\\n Quarter5:Fine-TuningOpen-SourceLargeLanguageModels(Llama3):'),\n",
              "  0.8443374037742615),\n",
              " (Document(id='5022e9dc-8cd6-4e78-93f9-ef69a4e49253', metadata={'page': 3, 'page_label': '4', 'source': '/content/Panaversity Cloud Native Applied Generative and Agentic AI Engineer (1).pdf'}, page_content=' Fine-TuningOpen-SourceLargeLanguageModelsusingPyTorch,andFastAI: Wewilllearntofine-tuningofopen-sourceLargeLanguageModels(LLMs)likeMetaLLaMA3usingPyTorchandFastAI,withafocusoncloud-nativetraininganddeployment.Wewillsetupdevelopmentenvironments,preprocessdata,fine-tunemodels,anddeploythemusingcloudnativeplatforms. PhysicalAIandHumanoidRobotics: Wewilllearntodesign,simulate,anddeployadvancedhumanoidrobotscapableofnaturalinteractions.\\nFlexibleLearning:\\n EarnWhileYouLearn:Startfreelancingorcontributingtoprojectsafterthethirdquarter.\\nProgramStructure(Core:3+CNAIMastery:3+Future:1=Total:7Quarters):\\nI.AppliedGenAIandAgenticCoreLevel(3Quarters)\\n Quarter1:ModernAIPythonProgramming\\nWebeginthecoursebyunderstandingthebasicsofGenAIandPromptEngineering.ThenwewillunderstandthebasicsofLinux,Docker, VSCode,Devcontainer, andGitHub.ThemainfocuswillbeonmasteringthefundamentalsofModernPythonwithTyping,thego-tolanguageforAIandusingAItowritePythonPrograms.'),\n",
              "  0.855362594127655)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrievers"
      ],
      "metadata": {
        "id": "BIooe3Qv_zhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "retriever = RunnableLambda(vectorstore.similarity_search).bind(k=1)  # select top result\n",
        "\n",
        "retriever.batch([\"python\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJRnavvr_yYu",
        "outputId": "9608c0f2-d936-4101-960c-35c85fff3276"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[Document(id='69c12aea-b181-4eea-a78b-5d865d47da1a', metadata={'page': 13, 'page_label': '14', 'source': '/content/Panaversity Cloud Native Applied Generative and Agentic AI Engineer (1).pdf'}, page_content=\"5.Whydon'tweuseTypeScript(Node.js)todevelopAPIsinsteadofusingPython?WewillnotuseTypescriptinGenAIAPIdevelopmentbecausePythonisaprioritywiththeAIcommunitywhenworkingwithAIandifanyupdatescomeinlibrariestheywillfirstcomeforPython.PythonisalwaysabetterchoicewhendealingwithAIandAPI.\\n PythonisthedefactostandardforAIDevelopment. TypeScriptisamoremodernlanguagethatisgainingpopularityforWebDevelopment,butPythonismorewidelyusedandhasalargerecosystemoflibrariesandframeworksavailable,especiallyforAI. TypeScriptisusedforwebuserinterfaces,whilePythonisusedforAPIs. Inthesecondquarter, studentswilllearntodevelopAPIsusingPythoninsteadofTypeScript. PythonisamorecommonlyusedlanguageforAIandAPIdevelopment,andithasalargerecosystemoflibrariesandframeworksavailableforthesepurposes. TypeScriptisamoremodernlanguagethatisbecomingincreasinglypopularforAPIdevelopmentalso,butitisstillnotaswidelyusedasPython,especiallyforAIapplicationsanddevelopment.\\n14\")]]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",\n",
        "                             api_key = userdata.get('GOOGLE_API_KEY')\n",
        ")\n"
      ],
      "metadata": {
        "id": "XqnFvUkx_3EO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llm.invoke(\"tell about cats?\")\n"
      ],
      "metadata": {
        "id": "gSDjtBaT_72O"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "message = \"\"\"\n",
        "Answer this question using the provided context only.\n",
        "\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "hHJqlgA9_-cv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Augment\n",
        "prompt = ChatPromptTemplate.from_messages([(\"human\", message)])\n"
      ],
      "metadata": {
        "id": "ydGN_cQVAAg3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG"
      ],
      "metadata": {
        "id": "iWQdQapXAJkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm\n"
      ],
      "metadata": {
        "id": "XUE4FawUAEPH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke(\"tell about quater 3 \")\n",
        "\n",
        "print(response.content)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljUSQny_AMcN",
        "outputId": "706373d9-f75b-49eb-bf13-3caa4ae3a9e9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the third quarter (Quarter 3) of the Engineering Program, students learn to use Python-based FastAPI as a core library for API development.  This will give them the skills to create powerful and efficient software applications to solve various business problems.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Click on below link for documentation\n",
        "[Documentation click here](https://python.langchain.com/api_reference/google_genai/embeddings/langchain_google_genai.embeddings.GoogleGenerativeAIEmbeddings.html#langchain_google_genai.embeddings.GoogleGenerativeAIEmbeddings)\n",
        "\n"
      ],
      "metadata": {
        "id": "TIUexAjl97Yj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Face detection with embedding\n"
      ],
      "metadata": {
        "id": "XNyx_f7_-N7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq facenet-pytorch\n"
      ],
      "metadata": {
        "id": "fYncRCqUKwzz"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.5.1+cu121 torchvision==0.16.1+cu121 torchaudio==2.5.1+cu121 -f https://download.pytorch.org/whl/torch_stable.html\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93SdvoeJ_pyi",
        "outputId": "98d40721-0166-4bae-9155-c43e1eb5729d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.5.1+cu121 (from versions: 1.13.0, 1.13.0+cpu, 1.13.0+cu116, 1.13.0+cu117, 1.13.0+cu117.with.pypi.cudnn, 1.13.1, 1.13.1+cpu, 1.13.1+cu116, 1.13.1+cu117, 1.13.1+cu117.with.pypi.cudnn, 2.0.0, 2.0.0+cpu, 2.0.0+cpu.cxx11.abi, 2.0.0+cu117, 2.0.0+cu117.with.pypi.cudnn, 2.0.0+cu118, 2.0.1, 2.0.1+cpu, 2.0.1+cpu.cxx11.abi, 2.0.1+cu117, 2.0.1+cu117.with.pypi.cudnn, 2.0.1+cu118, 2.0.1+rocm5.3, 2.0.1+rocm5.4.2, 2.1.0, 2.1.0+cpu, 2.1.0+cpu.cxx11.abi, 2.1.0+cu118, 2.1.0+cu121, 2.1.0+cu121.with.pypi.cudnn, 2.1.0+rocm5.5, 2.1.0+rocm5.6, 2.1.1, 2.1.1+cpu, 2.1.1+cpu.cxx11.abi, 2.1.1+cu118, 2.1.1+cu121, 2.1.1+cu121.with.pypi.cudnn, 2.1.1+rocm5.5, 2.1.1+rocm5.6, 2.1.2, 2.1.2+cpu, 2.1.2+cpu.cxx11.abi, 2.1.2+cu118, 2.1.2+cu121, 2.1.2+cu121.with.pypi.cudnn, 2.1.2+rocm5.5, 2.1.2+rocm5.6, 2.2.0, 2.2.0+cpu, 2.2.0+cpu.cxx11.abi, 2.2.0+cu118, 2.2.0+cu121, 2.2.0+rocm5.6, 2.2.0+rocm5.7, 2.2.1, 2.2.1+cpu, 2.2.1+cpu.cxx11.abi, 2.2.1+cu118, 2.2.1+cu121, 2.2.1+rocm5.6, 2.2.1+rocm5.7, 2.2.2, 2.2.2+cpu, 2.2.2+cpu.cxx11.abi, 2.2.2+cu118, 2.2.2+cu121, 2.2.2+rocm5.6, 2.2.2+rocm5.7, 2.3.0, 2.3.0+cpu, 2.3.0+cpu.cxx11.abi, 2.3.0+cu118, 2.3.0+cu121, 2.3.0+rocm5.7, 2.3.0+rocm6.0, 2.3.1, 2.3.1+cpu, 2.3.1+cpu.cxx11.abi, 2.3.1+cu118, 2.3.1+cu121, 2.3.1+rocm5.7, 2.3.1+rocm6.0, 2.4.0, 2.4.1, 2.5.0, 2.5.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.5.1+cu121\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq pillow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ0_lnVj-Qle",
        "outputId": "71c64bb0-31db-4f77-ad50-ce5872d0d957"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "facenet-pytorch 2.6.0 requires Pillow<10.3.0,>=10.2.0, but you have pillow 11.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "j58FVKP6-TNo"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "\n",
        "model = InceptionResnetV1(pretrained='vggface2').eval()"
      ],
      "metadata": {
        "id": "4dPGhKsh-nAx"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csMi10c9-ox4",
        "outputId": "75859aa0-19c2-4aee-d51f-5be0d881091a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InceptionResnetV1(\n",
              "  (conv2d_1a): BasicConv2d(\n",
              "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_2a): BasicConv2d(\n",
              "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_2b): BasicConv2d(\n",
              "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (maxpool_3a): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2d_3b): BasicConv2d(\n",
              "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_4a): BasicConv2d(\n",
              "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_4b): BasicConv2d(\n",
              "    (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (repeat_1): Sequential(\n",
              "    (0): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (mixed_6a): Mixed_6a(\n",
              "    (branch0): BasicConv2d(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (repeat_2): Sequential(\n",
              "    (0): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (5): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (6): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (7): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (8): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (9): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (mixed_7a): Mixed_7a(\n",
              "    (branch0): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (repeat_3): Sequential(\n",
              "    (0): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (block8): Block8(\n",
              "    (branch0): BasicConv2d(\n",
              "      (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (avgpool_1a): AdaptiveAvgPool2d(output_size=1)\n",
              "  (dropout): Dropout(p=0.6, inplace=False)\n",
              "  (last_linear): Linear(in_features=1792, out_features=512, bias=False)\n",
              "  (last_bn): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (logits): Linear(in_features=512, out_features=8631, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing function to transform the image into a tensor\n"
      ],
      "metadata": {
        "id": "EJ1TkU1dAkB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    return preprocess(image).unsqueeze(0)\n",
        "\n",
        "# Function to create image embeddings\n",
        "def create_image_embedding(image_path):\n",
        "    try:\n",
        "        input_tensor = preprocess_image(image_path)\n",
        "        with torch.no_grad():\n",
        "            embeddings = model(input_tensor)# ebedding important line\n",
        "        return embeddings.squeeze().numpy()\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", e)\n",
        "        return None"
      ],
      "metadata": {
        "id": "vhUVRCWt_1_j"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir images\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnAG8KYdAmi8",
        "outputId": "03a915cd-5511-4568-bf9f-a566a9adfa7e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory images: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# prompt: create python function where we provide image url and imag_name then it save in images folder\n"
      ],
      "metadata": {
        "id": "qtBdrI0YArHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "def save_image_from_url(image_url, image_name):\n",
        "  \"\"\"\n",
        "  Downloads an image from a URL and saves it to the 'images' folder.\n",
        "\n",
        "  Args:\n",
        "    image_url: The URL of the image to download.\n",
        "    image_name: The name of the file to save the image as.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    if not os.path.exists(\"images\"):\n",
        "      os.makedirs(\"images\")\n",
        "\n",
        "    image_path = os.path.join(\"images\", image_name)\n",
        "\n",
        "    response = requests.get(image_url, stream=True)\n",
        "    response.raise_for_status()  # Raise an exception for bad status codes\n",
        "\n",
        "    with open(image_path, 'wb') as file:\n",
        "      for chunk in response.iter_content(chunk_size=8192):\n",
        "        file.write(chunk)\n",
        "\n",
        "    print(f\"Image saved to: {image_path}\")\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error downloading image: {e}\")\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "7XPyFxkTAoZ9"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_image_from_url(\"https://media.licdn.com/dms/image/v2/D4E03AQEEn9DuNlQwvw/profile-displayphoto-shrink_200_200/profile-displayphoto-shrink_200_200/0/1664654245747?e=2147483647&v=beta&t=NGB0a9aqsgdyxpbuO3rqws95ogJnL_6aRtBDS7IWPfw\",\"s1.jpg\")\n",
        "save_image_from_url(\"https://avatars.githubusercontent.com/u/10209765?v=4\", \"q1.jpg\")\n",
        "\n",
        "save_image_from_url(\"https://media.licdn.com/dms/image/v2/D4D22AQFmuEiR8ttUmw/feedshare-shrink_800/feedshare-shrink_800/0/1711203894556?e=2147483647&v=beta&t=GEZGp_cdogNJCJIGidoEw_DjW2FXZcG4nUUlaNF1Zlc\",\"z1.jpg\")\n",
        "save_image_from_url(\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQBBiqefc7Le97Rn0udVVBkur7RlU53FcQh1A&s\",'z2.jpg')\n",
        "save_image_from_url(\"https://scontent.fkhi4-4.fna.fbcdn.net/v/t39.30808-6/468785380_10160566910882765_300507882801991935_n.jpg?_nc_cat=103&ccb=1-7&_nc_sid=6ee11a&_nc_eui2=AeEk77SJKagGymTo3ibNnnx9YsjCm8DJ0lRiyMKbwMnSVMJqs7YWsJDuzKzXyLHLoFk&_nc_ohc=QJMm9K-AE4QQ7kNvgFE0N2o&_nc_oc=Adi1r8eogMcuDIMMLJvliCOnaaXQ2KnUbbJvY94aAnfInkDB-fyB_1ZXBpDQnWTkZnY&_nc_zt=23&_nc_ht=scontent.fkhi4-4.fna&_nc_gid=AcSynbwc6ukNTxWnUzjhtEe&oh=00_AYCvnF-vj63T-X69PZgBk6JvVjepzybVukgHPSM_6BXkGQ&oe=678003A4\",'s2.jpg')\n",
        "save_image_from_url(\"https://i.ytimg.com/vi/7QD3GKvSyMk/hqdefault.jpg?sqp=-oaymwEmCOADEOgC8quKqQMa8AEB-AHOBYAC0AWKAgwIABABGGUgXChPMA8=&rs=AOn4CLB2EaZsLrClGHqUMUhApQ_sxAcF7Q\",\"q2.jpg\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juznYXxzAuyv",
        "outputId": "790cfaee-90fa-455c-e076-84f7c0b2dace"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image saved to: images/s1.jpg\n",
            "Image saved to: images/q1.jpg\n",
            "Image saved to: images/z1.jpg\n",
            "Image saved to: images/z2.jpg\n",
            "Error downloading image: 403 Client Error: Forbidden for url: https://scontent.fkhi4-4.fna.fbcdn.net/v/t39.30808-6/468785380_10160566910882765_300507882801991935_n.jpg?_nc_cat=103&ccb=1-7&_nc_sid=6ee11a&_nc_eui2=AeEk77SJKagGymTo3ibNnnx9YsjCm8DJ0lRiyMKbwMnSVMJqs7YWsJDuzKzXyLHLoFk&_nc_ohc=QJMm9K-AE4QQ7kNvgFE0N2o&_nc_oc=Adi1r8eogMcuDIMMLJvliCOnaaXQ2KnUbbJvY94aAnfInkDB-fyB_1ZXBpDQnWTkZnY&_nc_zt=23&_nc_ht=scontent.fkhi4-4.fna&_nc_gid=AcSynbwc6ukNTxWnUzjhtEe&oh=00_AYCvnF-vj63T-X69PZgBk6JvVjepzybVukgHPSM_6BXkGQ&oe=678003A4\n",
            "Image saved to: images/q2.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding of image q2"
      ],
      "metadata": {
        "id": "fRG0pV1KA5Ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "image_path = \"./images/q2.jpg\"\n",
        "q2 = create_image_embedding(image_path)\n",
        "\n",
        "# 'embedding' now contains a dense vector representation of the image\n",
        "print(\"Image Embedding Shape:\", q2.shape)\n",
        "print(\"Image Embedding:\", q2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYFU1XoqAxsA",
        "outputId": "73bc66f1-5a6b-4994-c1de-92bd86833e24"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Embedding Shape: (512,)\n",
            "Image Embedding: [ 0.00058278 -0.01463297 -0.10330155  0.03984535  0.08525636  0.08029363\n",
            " -0.01011138  0.04867227 -0.00259888 -0.0077198  -0.0331905   0.06225294\n",
            "  0.01708761 -0.00982595 -0.01638006  0.00054205  0.04426373  0.00519726\n",
            "  0.04448376 -0.08979201 -0.06033407 -0.00162232  0.09186839  0.03262272\n",
            "  0.06873461  0.02532319  0.03512866 -0.05809444  0.00151727  0.05172818\n",
            " -0.04107905 -0.03755797 -0.04134395 -0.00761167 -0.00674731  0.04443471\n",
            "  0.00570058 -0.02845279 -0.12002273  0.05528227  0.00132485  0.00437373\n",
            " -0.02495593  0.01842853 -0.00357915  0.01889837  0.02980521  0.10357354\n",
            " -0.11238679 -0.02633037  0.02794239 -0.0152881   0.04015452 -0.0039458\n",
            " -0.09202526  0.0715652  -0.03382103  0.07384298  0.01921727 -0.04263638\n",
            "  0.02758526  0.03841295 -0.04435986 -0.05347932 -0.04511738  0.03700717\n",
            " -0.00194125 -0.00450149  0.03157888  0.02796174  0.02416223  0.01202647\n",
            " -0.00905218  0.00880154  0.0189873  -0.01363976 -0.0499587  -0.01557556\n",
            "  0.02297474  0.0651246   0.0614766   0.02845725  0.00367925  0.03151315\n",
            " -0.00906348  0.04034334  0.00219301  0.05856943 -0.00909011 -0.01423355\n",
            "  0.01797742  0.01435157  0.05880354 -0.04344825  0.10147727 -0.04386036\n",
            " -0.01284018  0.02154127 -0.06004561  0.05457702  0.04566431 -0.01077684\n",
            "  0.00699712  0.02765366  0.00357566  0.05447806 -0.01310005 -0.02255299\n",
            "  0.01432354 -0.07601233  0.04908508  0.00389152 -0.06607237 -0.08058616\n",
            "  0.0263547  -0.02808471  0.0695286  -0.00038021 -0.03878854  0.02984364\n",
            " -0.00256646  0.02118442  0.00133815 -0.0472773  -0.01195588 -0.0669666\n",
            " -0.0071366   0.04453232  0.00111025 -0.02842125 -0.0175714  -0.00643478\n",
            "  0.04876323 -0.06472842 -0.09787413  0.00334867  0.00187649 -0.00024767\n",
            "  0.06938788  0.10385709 -0.02833053 -0.00792771 -0.00623726  0.03481311\n",
            "  0.07992636 -0.05045125 -0.00808156  0.00769071  0.05459293 -0.06051681\n",
            "  0.02623133 -0.04237332 -0.01461612  0.07601271  0.02316507 -0.06920444\n",
            "  0.05341151  0.0485434   0.03503026 -0.02546098  0.07508431  0.04377884\n",
            " -0.02852262  0.02682048  0.09139965  0.04641375 -0.05197915 -0.02836282\n",
            " -0.06560951  0.04164857 -0.01279163 -0.00395267 -0.00660236  0.00338493\n",
            "  0.05723305  0.04263638  0.04826457 -0.02185955 -0.08236013  0.0287613\n",
            " -0.04757535 -0.00422647 -0.08301193  0.06606403  0.04168128  0.04225906\n",
            "  0.03009798  0.05508625  0.02304784  0.02956334  0.02328967 -0.03885793\n",
            "  0.09149846 -0.09700762  0.05365682 -0.02802743  0.06186439  0.04086529\n",
            " -0.02531239  0.06880185  0.03396954 -0.05555064  0.02037002 -0.04165684\n",
            "  0.03669901  0.0640901   0.03570412 -0.00553594  0.04140023  0.02657003\n",
            " -0.06931031 -0.03869386 -0.04545971  0.01155922 -0.00488004  0.0426462\n",
            " -0.0636877   0.03799228 -0.02469095 -0.01786827 -0.11714919 -0.0975224\n",
            " -0.01709365 -0.05293322 -0.00160847  0.03877039 -0.06770448 -0.00353634\n",
            " -0.01539879 -0.00023611 -0.009705    0.0525001  -0.01574586 -0.05584005\n",
            "  0.02420623 -0.00578888  0.01579252 -0.07729022 -0.02444515 -0.02403441\n",
            " -0.01252517 -0.0195509   0.01120158 -0.01532311  0.09776177  0.07899044\n",
            " -0.01579785  0.03239097 -0.01639406  0.05716111  0.05955906  0.07648396\n",
            "  0.01000867 -0.00473776  0.04412794 -0.02058393  0.02995613  0.03681798\n",
            "  0.0209659   0.05551313 -0.00472502 -0.01202328  0.02113431 -0.01948468\n",
            " -0.05865138 -0.02253946  0.06847092  0.00293734 -0.03504635  0.01365006\n",
            " -0.09010956 -0.00802817 -0.04642696 -0.02624361 -0.06792872 -0.05286164\n",
            "  0.02717434  0.01057739  0.01564983 -0.06623219  0.06408169  0.03001962\n",
            " -0.01631466 -0.04925485 -0.02576832 -0.04653771 -0.01977751 -0.00355507\n",
            " -0.03372259 -0.07618748  0.02066366 -0.06482755  0.03217461 -0.01092269\n",
            " -0.01718775 -0.02406414  0.00717621  0.07962366  0.03695744  0.03045471\n",
            "  0.09488815  0.00117036  0.02282127  0.01545661  0.03193149 -0.03805847\n",
            " -0.03073642 -0.06083288 -0.02635645  0.0254594  -0.02669582  0.01615116\n",
            "  0.01507757  0.01439681  0.04895734  0.02372173 -0.04542394  0.06016143\n",
            "  0.00688547 -0.00513737  0.10314457  0.01167683 -0.04161828  0.01970115\n",
            " -0.07644531  0.07899482  0.02732771  0.02116577  0.05548168  0.03341798\n",
            "  0.04803425  0.02059413 -0.00346371  0.06049509  0.00493905 -0.04375328\n",
            "  0.01996547  0.03197958  0.04180827  0.02040025  0.05875337  0.01775215\n",
            "  0.03359037 -0.00116151 -0.03342745 -0.02892528 -0.01895843  0.05830195\n",
            "  0.03731528 -0.04010315  0.01020672  0.02329778 -0.04411007 -0.08327088\n",
            " -0.05110124  0.01217918  0.09359314 -0.02469934 -0.02297806 -0.03897167\n",
            "  0.02345902  0.00067792 -0.06096138 -0.01937438 -0.02764596  0.01525408\n",
            "  0.07700519 -0.03905027  0.00822655 -0.03271889 -0.07537898 -0.01849484\n",
            "  0.01702019  0.0040585   0.0699041   0.04940457 -0.06243282 -0.00178328\n",
            " -0.01065948 -0.00928921 -0.02235799 -0.05218275 -0.06756899  0.0613427\n",
            "  0.00699825 -0.03643901 -0.02644681 -0.01890211  0.02612516 -0.03388806\n",
            "  0.00105624  0.05355155 -0.00194111 -0.02571725 -0.04154576 -0.00361628\n",
            "  0.08862311  0.03117609  0.06117413  0.02730942 -0.08572201  0.08137289\n",
            "  0.00439804 -0.00416813 -0.01750178  0.01217526  0.00269837 -0.04631697\n",
            "  0.05641455 -0.00846761  0.04905433 -0.02528094  0.00193327 -0.02050643\n",
            " -0.02846969 -0.00645685  0.05126152  0.03582475  0.0033618  -0.04733974\n",
            "  0.02973489 -0.0122521  -0.03350455  0.06956115 -0.0429418   0.00483133\n",
            "  0.02245149 -0.00588596  0.02491498 -0.06521189  0.01002998  0.04180297\n",
            " -0.0244523   0.00798181 -0.05623091 -0.04452998  0.01560469  0.00986408\n",
            " -0.02810116 -0.01782225 -0.05889104 -0.0351436  -0.00859083  0.10779268\n",
            " -0.01023237  0.06080008 -0.10309302  0.01397533  0.02526072 -0.07942653\n",
            "  0.01960654  0.05659704  0.00549258 -0.09367355  0.0263099  -0.00264487\n",
            " -0.00870358  0.09565648  0.07037158  0.00666058  0.01199247  0.04150009\n",
            " -0.03298025  0.02638438  0.06660346 -0.05924815 -0.09617335  0.01599596\n",
            "  0.03302556 -0.00165851  0.00336149 -0.00456443  0.00200567 -0.02196456\n",
            " -0.09801189 -0.00093401  0.09824389 -0.00995049  0.00316581  0.03275843\n",
            " -0.00061821  0.01058625  0.00352063 -0.02993771  0.03894569  0.05737574\n",
            " -0.10843383  0.02968427  0.05140879 -0.06388002  0.01988242 -0.04600152\n",
            " -0.03955155  0.00290028  0.07266345 -0.01782443 -0.0110463  -0.0075507\n",
            "  0.03013197  0.01059503 -0.03528689 -0.004358    0.02702685 -0.01792463\n",
            "  0.00025843  0.06066977  0.06143346  0.03103392 -0.02381746 -0.01173486\n",
            "  0.04217441 -0.06347054]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/images/s1.jpg\"\n",
        "cat2 = create_image_embedding(image_path)\n",
        "\n",
        "# 'embedding' now contains a dense vector representation of the image\n",
        "print(\"Image Embedding Shape:\", cat2.shape)\n",
        "print(\"Image Embedding:\", cat2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mSjKHLsA-uC",
        "outputId": "775eceeb-8acf-4c2b-e72c-50900603fdc6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Embedding Shape: (512,)\n",
            "Image Embedding: [ 7.76378484e-03  1.38627877e-02  3.42880785e-02  5.59410453e-02\n",
            "  4.43015993e-02  4.22530621e-02  3.66532840e-02  9.78047494e-03\n",
            " -1.34703349e-02  1.68228522e-02  8.26280266e-02  7.83666130e-03\n",
            "  4.87103760e-02 -3.90704256e-03  1.06615685e-02 -7.18539953e-02\n",
            " -4.96409610e-02  1.04582205e-01  1.67736411e-02  2.15226728e-02\n",
            " -2.09242180e-02  8.07328224e-02  1.67470835e-02 -1.14253521e-01\n",
            " -4.25868072e-02 -2.27696840e-02 -1.50764631e-02 -4.02070023e-02\n",
            " -2.33913157e-02 -4.37326618e-02  7.05495998e-02  7.63667449e-02\n",
            "  5.58592677e-02  1.28479674e-02  3.95264030e-02 -4.74360399e-02\n",
            "  1.70672743e-03  1.20020993e-02 -4.78693005e-03 -1.22949760e-02\n",
            "  1.39081292e-02 -2.78096441e-02  2.48735808e-02 -2.39850115e-03\n",
            " -1.18011301e-02  3.69508145e-03 -4.81235720e-02  1.29993325e-02\n",
            " -6.90511912e-02 -8.01179186e-02 -2.32403465e-02 -6.55335188e-02\n",
            "  3.54257748e-02  5.77532388e-02  1.61157586e-02 -5.35045713e-02\n",
            "  3.46317366e-02  4.95921448e-02 -6.57782704e-02 -2.87748780e-02\n",
            "  1.33648114e-02  2.92463489e-02 -7.16798892e-03 -2.60961298e-02\n",
            " -3.84725630e-02 -5.41980080e-02 -2.72227060e-02 -9.77029949e-02\n",
            " -5.60861547e-03  1.73442401e-02  1.20176934e-02  1.33096920e-02\n",
            " -6.81875497e-02 -5.93172684e-02  9.24794376e-02 -4.42040712e-02\n",
            "  1.17073935e-02  1.30964639e-02 -1.02159875e-02 -6.60966262e-02\n",
            "  2.74766097e-03  5.66387810e-02 -5.15496060e-02 -1.35784566e-01\n",
            " -1.71666276e-02  6.00463450e-02  3.63181606e-02 -1.67583432e-02\n",
            " -4.53567319e-02 -1.23792412e-02 -2.19547115e-02 -3.62854227e-02\n",
            " -1.21332277e-02 -2.44936086e-02  6.26917779e-02  2.22552717e-02\n",
            "  2.98874136e-02  2.22025588e-02 -9.66426283e-02  7.29883313e-02\n",
            " -3.75597505e-03  3.08721773e-02  5.43332100e-02 -3.68908653e-03\n",
            "  7.37921987e-03 -3.98004688e-02  9.52879805e-03  1.75728649e-02\n",
            " -4.73739766e-02  5.80539145e-02  1.49614848e-02  4.65174206e-02\n",
            " -4.73917313e-02 -9.55479369e-02 -1.30020827e-03  3.58438864e-02\n",
            "  2.92868987e-02  8.70078877e-02 -2.50851661e-02  5.11971526e-02\n",
            " -7.66126141e-02  1.13216108e-02 -1.16875386e-02  3.18520553e-02\n",
            " -7.28361383e-02  9.24174674e-03  5.45233153e-02 -9.25382376e-02\n",
            "  1.96304452e-03 -4.51774783e-02  7.02419132e-02 -4.51019742e-02\n",
            "  4.93133478e-02  9.41087212e-03  2.20235586e-02  6.03108779e-02\n",
            "  4.44470979e-02  9.01812129e-03 -8.82950891e-03 -2.89288219e-02\n",
            "  8.10177438e-03  3.38467509e-02 -4.21001464e-02  6.73301220e-02\n",
            " -2.65432876e-02  5.14418371e-02  2.14178627e-03  1.92509014e-02\n",
            " -5.67111745e-03  2.74719088e-03  3.62339877e-02 -1.61316209e-02\n",
            " -1.28224179e-01 -4.17471454e-02  9.63695645e-02 -1.34603325e-02\n",
            " -9.35380831e-02  4.97768186e-02  4.49721469e-03  3.34447138e-02\n",
            " -7.44952187e-02  4.41344939e-02  2.08500982e-03  7.14628175e-02\n",
            " -6.58861399e-02  1.71503481e-02 -7.69790933e-02 -2.24910048e-03\n",
            "  3.71600734e-03  7.36787766e-02 -3.01399883e-02  5.64339512e-04\n",
            "  2.36860197e-02  6.51071826e-03 -1.52252289e-02  2.28912495e-02\n",
            " -3.94456349e-02  1.33162243e-02 -4.88440581e-02  2.79314108e-02\n",
            "  6.11856161e-03  1.17555913e-02  5.45368344e-02  2.21735612e-02\n",
            "  1.01567462e-01  1.83181686e-03  1.36150345e-01 -5.65424736e-04\n",
            "  9.66723040e-02  5.26050758e-03  2.86572445e-02  3.75467837e-02\n",
            "  5.86601458e-02  1.19750528e-02  1.85744930e-02 -4.47005453e-03\n",
            " -5.86419478e-02 -5.42708114e-02  5.27157523e-02 -7.78222308e-02\n",
            "  1.14250705e-01 -4.96455505e-02  5.06820008e-02 -1.78408735e-02\n",
            " -2.06031911e-02  3.14575844e-02 -4.43294458e-02  5.66000957e-03\n",
            "  1.68448128e-02 -9.91806737e-04 -3.69748957e-02 -7.28525221e-02\n",
            " -3.49484431e-03 -1.70017760e-02 -1.93793736e-02 -7.71907740e-04\n",
            "  1.01750888e-01 -4.65802774e-02  1.33326929e-02  1.83004048e-02\n",
            "  1.40869832e-02  3.63097824e-02  1.27118351e-02  5.97142391e-02\n",
            "  2.85159722e-02 -1.92761663e-02  7.04711452e-02 -3.32086068e-03\n",
            " -3.56172509e-02 -4.41055465e-03 -1.44732622e-02  1.00005746e-01\n",
            "  6.86178962e-03 -9.96520557e-03 -6.38688728e-02  7.65028223e-02\n",
            " -3.80020551e-02  3.91958207e-02  6.80253506e-02  2.49275248e-02\n",
            " -1.09814711e-01  3.56751238e-03 -3.75152640e-02  3.69580872e-02\n",
            "  1.40137470e-03 -5.07759154e-02  3.74523364e-02 -1.19550623e-01\n",
            "  7.02822534e-03  8.97310227e-02 -2.02415777e-05 -2.71951500e-02\n",
            "  2.10960004e-02 -1.76199130e-03  1.69102196e-02  3.16304266e-02\n",
            " -3.24133970e-02  2.45009605e-02 -4.55224101e-04  1.52270729e-02\n",
            " -1.44037670e-02  5.11877537e-02  4.06553224e-02  2.30162498e-02\n",
            " -5.74520864e-02 -3.59858014e-02  7.97812734e-03  2.39289701e-02\n",
            "  7.78867304e-03 -7.12133721e-02  5.17319441e-02  3.54757085e-02\n",
            " -2.98206368e-03 -1.24428635e-02  4.75401804e-02  1.11679453e-02\n",
            "  1.35332961e-02 -5.93988150e-02  3.60224955e-02  5.34510911e-02\n",
            "  1.73241198e-02  7.53577650e-02 -7.69886225e-02 -6.47578835e-02\n",
            " -2.17682458e-02  1.27790282e-02  3.61313000e-02 -3.68935838e-02\n",
            " -3.71016078e-02  1.04671763e-02  6.07686164e-03 -2.37216298e-02\n",
            "  2.95480099e-02  6.64251745e-02  1.48287043e-02 -1.85798500e-02\n",
            "  5.46345487e-03 -4.70231473e-02 -5.05926041e-03 -4.09380049e-02\n",
            " -2.61370256e-03  6.40212819e-02 -7.19646196e-05  3.19367871e-02\n",
            "  9.31114051e-03 -1.94759015e-03 -4.32936810e-02  4.60799001e-02\n",
            " -5.94974086e-02  1.96509212e-02 -3.83692491e-03  7.20343590e-02\n",
            "  8.95578563e-02  9.14972052e-02  4.88447510e-02  4.07453291e-02\n",
            "  5.18323742e-02 -6.00317642e-02 -3.85120697e-03 -3.94102000e-02\n",
            "  2.93666720e-02 -2.28005536e-02 -4.38708514e-02  2.86182947e-02\n",
            "  3.75901684e-02 -2.13397779e-02  2.47422419e-02  4.66584554e-03\n",
            "  1.44161619e-02 -2.49854252e-02 -4.55838777e-02  5.42040542e-02\n",
            "  1.25792669e-02 -5.46378456e-03 -3.62196751e-02  9.18032750e-02\n",
            "  4.82125096e-02 -2.46436764e-02 -3.90063860e-02 -4.79358397e-02\n",
            "  6.18138511e-05 -3.24951150e-02 -8.44965514e-04  2.72285622e-02\n",
            "  5.77807566e-03  1.25256199e-02 -6.47303695e-03  2.37730108e-02\n",
            " -4.76353355e-02 -1.97492447e-02 -4.73502092e-02  6.55321255e-02\n",
            " -1.84846995e-03  7.02921748e-02  3.46888378e-02  5.13258129e-02\n",
            "  7.81116113e-02  1.44243920e-02  4.64792065e-02  1.62513610e-02\n",
            "  1.40128576e-03  4.87961015e-03 -2.28351960e-03  1.01209451e-02\n",
            " -3.46758030e-02  5.79160340e-02 -9.75552797e-02  6.13142364e-02\n",
            " -5.32289548e-03  2.40072589e-02  6.09650416e-03 -6.24088459e-02\n",
            " -4.34917808e-02  1.39547838e-02 -4.28758450e-02  2.18541268e-02\n",
            "  2.69848295e-02  2.43097786e-02  5.46002667e-03 -3.01392749e-02\n",
            "  1.23984069e-02 -1.23263234e-02  4.88525294e-02 -4.69718613e-02\n",
            "  3.06189619e-02 -4.80947159e-02 -6.17315806e-03 -5.55271730e-02\n",
            " -2.11060932e-03  1.95178073e-02  1.79617424e-02 -1.64129697e-02\n",
            "  7.35288719e-03  1.64800938e-02  1.68889705e-02  1.27309887e-02\n",
            " -2.23991200e-02  8.54902342e-02  1.79819134e-03  3.19757760e-02\n",
            " -5.01264855e-02 -8.58974550e-03  3.10516283e-02  1.94656197e-02\n",
            "  5.20680733e-02  2.90778223e-02 -7.18047097e-02 -7.72344321e-03\n",
            "  5.82657307e-02 -2.00119913e-02  3.30253653e-02  2.28906353e-03\n",
            " -6.85123261e-03 -5.98944239e-02 -2.11149976e-02  4.52211034e-03\n",
            " -1.92536805e-02 -3.62476008e-03  3.82426009e-02 -5.42051196e-02\n",
            "  1.66287832e-02 -5.00509255e-02 -2.07497608e-02  3.68329175e-02\n",
            " -2.63065994e-02  1.16164694e-02  2.00468097e-02 -3.40788998e-02\n",
            " -1.52380075e-02 -7.04959687e-03 -6.64521903e-02  6.00460730e-02\n",
            " -2.28707977e-02 -6.05974272e-02  4.49177511e-02  3.11775170e-02\n",
            " -7.16427565e-02 -9.11885127e-02 -3.43095958e-02 -6.53048307e-02\n",
            " -7.32368929e-03  4.93340846e-03 -2.79968977e-03  1.77632188e-04\n",
            "  2.22169012e-02 -1.25159338e-01 -8.77434574e-03  7.70308357e-03\n",
            " -8.37685689e-02 -2.38030218e-03 -1.38819199e-02 -3.58492509e-02\n",
            " -6.59921542e-02 -8.87616351e-03 -2.50451770e-02 -1.38345864e-02\n",
            " -1.50988065e-02  2.61421595e-02  2.14549247e-02  2.74033174e-02\n",
            " -2.24486757e-02  1.36897042e-01  5.97219281e-02  3.43995504e-02\n",
            " -3.68034616e-02  9.90555137e-02  5.72617259e-03  7.98852742e-03\n",
            "  3.17643918e-02 -1.15444011e-03  2.22948026e-02 -8.19727480e-02\n",
            " -2.44736336e-02 -3.77135910e-02 -3.72394361e-02 -4.48852703e-02\n",
            " -3.46836746e-02  5.57406470e-02  2.22214051e-02  1.33443996e-02\n",
            " -2.07721926e-02 -3.50483842e-02  1.16265006e-02  6.43413141e-03\n",
            "  1.25987381e-02 -3.73558849e-02  3.82581800e-02 -6.39281760e-04\n",
            " -1.17770452e-02 -2.46396195e-02 -3.05028148e-02 -2.71748044e-02\n",
            " -1.51610048e-02 -4.10503522e-02  1.32630265e-03 -4.55399565e-02\n",
            "  3.61582115e-02  2.38949270e-03  1.35977357e-03  2.27696281e-02\n",
            "  1.31506175e-02 -5.87612949e-02  5.31763174e-02 -4.84416224e-02\n",
            " -7.12555051e-02  2.23901179e-02  4.09953110e-02 -3.39812636e-02\n",
            "  2.66649295e-02 -6.09346107e-02 -1.21593170e-01  2.65079048e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q1 = create_image_embedding(\"./images/q1.jpg\")\n",
        "q2 = create_image_embedding(\"./images/q2.jpg\")\n",
        "s1 = create_image_embedding(\"./images/s1.jpg\")\n",
        "z1 = create_image_embedding(\"./images/z1.jpg\")\n",
        "z2 = create_image_embedding(\"./images/z2.jpg\")"
      ],
      "metadata": {
        "id": "Vew4dsumBC-k"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save image embedding into vector database"
      ],
      "metadata": {
        "id": "b6qoDecNBWv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install -U milvus-lite\n",
        "\n",
        "!pip install -U pymilvus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8P2qr5qBRqg",
        "outputId": "118ca2dc-7deb-4384-ab99-c8814e17919c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: milvus-lite in /usr/local/lib/python3.11/dist-packages (2.4.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from milvus-lite) (4.67.1)\n",
            "Requirement already satisfied: pymilvus in /usr/local/lib/python3.11/dist-packages (2.5.4)\n",
            "Requirement already satisfied: setuptools>69 in /usr/local/lib/python3.11/dist-packages (from pymilvus) (75.1.0)\n",
            "Requirement already satisfied: grpcio<=1.67.1,>=1.49.1 in /usr/local/lib/python3.11/dist-packages (from pymilvus) (1.67.1)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from pymilvus) (5.29.3)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from pymilvus) (1.0.1)\n",
            "Requirement already satisfied: ujson>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pymilvus) (5.10.0)\n",
            "Requirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.11/dist-packages (from pymilvus) (2.2.2)\n",
            "Requirement already satisfied: milvus-lite>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from pymilvus) (2.4.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from milvus-lite>=2.4.0->pymilvus) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->pymilvus) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->pymilvus) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->pymilvus) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->pymilvus) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymilvus import MilvusClient\n",
        "client = MilvusClient(\"./milvus_demo.db\")\n"
      ],
      "metadata": {
        "id": "Jb2qZZ-9BcVb"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pymilvus import MilvusClient\n",
        "import numpy as np\n",
        "\n",
        "client = MilvusClient(\"./milvus_demo.db\")\n",
        "client.create_collection(\n",
        "    collection_name=\"images\",\n",
        "    dimension=512  # The vectors we will use in this demo has 384 dimensions\n",
        ")\n",
        ""
      ],
      "metadata": {
        "id": "N9OzWHb1EPhJ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = [\n",
        "    {\"id\": 1, \"person_name\": \"Qasim\", \"vector\": q1},\n",
        "    {\"id\": 2, \"person_name\": \"Qasim\", \"vector\": q2},\n",
        "    {\"id\": 3, \"person_name\": \"Shahzad\", \"vector\": s1},\n",
        "    {\"id\": 5, \"person_name\": \"Zia Khan\", \"vector\": z1},\n",
        "    {\"id\": 6, \"person_name\": \"Zia Khan\", \"vector\": z2}\n",
        "]\n"
      ],
      "metadata": {
        "id": "P3pw-oyPERMQ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "res = client.insert(\n",
        "    collection_name=\"images\",\n",
        "    data=data\n",
        ")"
      ],
      "metadata": {
        "id": "-fjU1bqFETZb"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = client.search(\n",
        "    collection_name=\"images\",\n",
        "    data=[s1],\n",
        "    limit=1,\n",
        "    output_fields=[\"id\", \"person_name\"],\n",
        ")\n",
        "print(res)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssuBzAXSEYG5",
        "outputId": "01dd6970-8a2e-4e5b-c1d7-4a9b22cc0155"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data: [\"[{'id': 3, 'distance': 1.0, 'entity': {'person_name': 'Shahzad', 'id': 3}}]\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0S07vUi1EZg_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}